{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67e03ff",
   "metadata": {},
   "source": [
    "### Question-1. Write a program that takes a string as input, and counts the frequency of each word in the string, there might be repeated characters in the string. Your task is to find the highest frequency and returns the length of the highest-frequency word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ee000",
   "metadata": {},
   "outputs": [],
   "source": [
    " def word_count(str):\n",
    "    counts = dict()\n",
    "    words = str.split()\n",
    "\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "        max_key=max(counts,key=counts.get)\n",
    "        \n",
    "\n",
    "    return counts, len(max_key)\n",
    "\n",
    "word_count(input())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ae635",
   "metadata": {},
   "source": [
    "### Question 2. Consider a string to be valid if all characters of the string appear the same number of times. It is also valid if he can remove just one character at the index in the string, and the remaining characters will occur the same number of times. Given a string, determine if it is valid. If so, return YES , otherwise return NO ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def isValid(s):\n",
    "    c = Counter(Counter(s).values())\n",
    "    if len(c)==1:\n",
    "        return \"YES\"\n",
    "    if len(c)>2:\n",
    "        return \"NO\"\n",
    "    if 1 in c.values() and (c[min(c.keys())]==1 or (max(c.keys()) - min(c.keys())==1)):\n",
    "        return \"YES\"\n",
    "    else:\n",
    "        return \"NO\"\n",
    "\n",
    "print(isValid(input()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007ff25",
   "metadata": {},
   "source": [
    "### Question 3. Write a program, which would download the data from the provided link, and then read the data and convert that into properly structured data and return it in Excel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "126858b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "url='https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json' #provide valid url link to download data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45fad1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(url)\n",
    "data=response.json()\n",
    "data1=data['pokemon']\n",
    "df=pd.DataFrame(data1,columns=['id',\n",
    "   'num',\n",
    "   'name',\n",
    "   'img',\n",
    "   'type',\n",
    "   'height',\n",
    "   'weight',\n",
    "   'candy',\n",
    "   'egg',\n",
    "   'spawn_chance',\n",
    "   'avg_spawns',\n",
    "   'spawn_time',\n",
    "   'multipliers',\n",
    "   'weaknesses',\n",
    "   'prev_evolution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "987756bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"pokemon_Excel.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8327cb6",
   "metadata": {},
   "source": [
    "### Question 4 -Write a program to download the data from the link given below and then read the data and convert the intothe proper structure and return it as a CSV file.\n",
    "Link - https://data.nasa.gov/resource/y77d-th95.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf4c5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1='https://data.nasa.gov/resource/y77d-th95.json' #provide valid url link to download data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4067524",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa=requests.get(url1)\n",
    "data_nasa=nasa.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2bb8830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nasa=pd.DataFrame(data_nasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c645ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nasa.to_csv('nasa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b566bab",
   "metadata": {},
   "source": [
    "### Question 5 -Write a program to download the data from the given API link and then extract the following data withproper formatting\n",
    "Link - http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "029ca2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2='http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes' #provide valid url link to download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b4e7696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "maze=requests.get(url2)\n",
    "pull_maze=maze.text\n",
    "data_maze=json.loads(pull_maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "baaa072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season 1 Episode 1: The Original\n",
      "Season 1 Episode 2: Chestnut\n",
      "Season 1 Episode 3: The Stray\n",
      "Season 1 Episode 4: Dissonance Theory\n",
      "Season 1 Episode 5: Contrapasso\n",
      "Season 1 Episode 6: The Adversary\n",
      "Season 1 Episode 7: Trompe L'Oeil\n",
      "Season 1 Episode 8: Trace Decay\n",
      "Season 1 Episode 9: The Well-Tempered Clavier\n",
      "Season 1 Episode 10: The Bicameral Mind\n",
      "Season 2 Episode 1: Journey Into Night\n",
      "Season 2 Episode 2: Reunion\n",
      "Season 2 Episode 3: Virtù e Fortuna\n",
      "Season 2 Episode 4: The Riddle of the Sphinx\n",
      "Season 2 Episode 5: Akane No Mai\n",
      "Season 2 Episode 6: Phase Space\n",
      "Season 2 Episode 7: Les Écorchés\n",
      "Season 2 Episode 8: Kiksuya\n",
      "Season 2 Episode 9: Vanishing Point\n",
      "Season 2 Episode 10: The Passenger\n",
      "Season 3 Episode 1: Parce Domine\n",
      "Season 3 Episode 2: The Winter Line\n",
      "Season 3 Episode 3: The Absence of Field\n",
      "Season 3 Episode 4: The Mother of Exiles\n",
      "Season 3 Episode 5: Genre\n",
      "Season 3 Episode 6: Decoherence\n",
      "Season 3 Episode 7: Passed Pawn\n",
      "Season 3 Episode 8: Crisis Theory\n",
      "Season 4 Episode 1: The Auguries\n",
      "Season 4 Episode 2: Well Enough Alone\n",
      "Season 4 Episode 3: Années Folles\n",
      "Season 4 Episode 4: Generation Loss\n",
      "Season 4 Episode 5: Zhuangzi\n",
      "Season 4 Episode 6: Fidelity\n",
      "Season 4 Episode 7: Metanoia\n",
      "Season 4 Episode 8: Que Será, Será\n"
     ]
    }
   ],
   "source": [
    "for episode in data_maze[\"_embedded\"][\"episodes\"]:\n",
    "    print(f\"Season {episode['season']} Episode {episode['number']}: {episode['name']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22048beb",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb7ba2",
   "metadata": {},
   "source": [
    "## Q-1. Imagine you have a dataset where you have different Instagram featureslike u sername , Caption , Hashtag , Followers , Time_Since_posted , and likes , now your task isto predict the number of likes and Time Since posted and the rest of the features areyour input features. Now you have to build a model which can predict thenumber of likes and Time Since posted.\n",
    "Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "087fa4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "00822b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('instagram_reach.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "02c0d1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S.No</th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Time since posted</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mikequindazzi</td>\n",
       "      <td>Who are #DataScientist and what do they do? &gt;&gt;...</td>\n",
       "      <td>1600</td>\n",
       "      <td>#MachineLearning #AI #DataAnalytics #DataScien...</td>\n",
       "      <td>11 hours</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>drgorillapaints</td>\n",
       "      <td>We all know where it’s going. We just have to ...</td>\n",
       "      <td>880</td>\n",
       "      <td>#deck .#mac #macintosh#sayhello #apple #steve...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>aitrading_official</td>\n",
       "      <td>Alexander Barinov: 4 years as CFO in multinati...</td>\n",
       "      <td>255</td>\n",
       "      <td>#whoiswho #aitrading #ai #aitradingteam#instat...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>opensourcedworkplace</td>\n",
       "      <td>sfad</td>\n",
       "      <td>340</td>\n",
       "      <td>#iot #cre#workplace #CDO #bigdata #technology#...</td>\n",
       "      <td>3 hours</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>crea.vision</td>\n",
       "      <td>Ever missed a call while your phone was chargi...</td>\n",
       "      <td>304</td>\n",
       "      <td>#instamachinelearning #instabigdata#instamarke...</td>\n",
       "      <td>3 hours</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  S.No              USERNAME  \\\n",
       "0           0     1         mikequindazzi   \n",
       "1           1     2       drgorillapaints   \n",
       "2           2     3    aitrading_official   \n",
       "3           3     4  opensourcedworkplace   \n",
       "4           4     5           crea.vision   \n",
       "\n",
       "                                             Caption  Followers  \\\n",
       "0  Who are #DataScientist and what do they do? >>...       1600   \n",
       "1  We all know where it’s going. We just have to ...        880   \n",
       "2  Alexander Barinov: 4 years as CFO in multinati...        255   \n",
       "3                                               sfad        340   \n",
       "4  Ever missed a call while your phone was chargi...        304   \n",
       "\n",
       "                                            Hashtags Time since posted  Likes  \n",
       "0  #MachineLearning #AI #DataAnalytics #DataScien...          11 hours    139  \n",
       "1   #deck .#mac #macintosh#sayhello #apple #steve...           2 hours     23  \n",
       "2  #whoiswho #aitrading #ai #aitradingteam#instat...           2 hours     25  \n",
       "3  #iot #cre#workplace #CDO #bigdata #technology#...           3 hours     49  \n",
       "4  #instamachinelearning #instabigdata#instamarke...           3 hours     30  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c1dd2fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "S.No                 0\n",
       "USERNAME             0\n",
       "Caption              6\n",
       "Followers            0\n",
       "Hashtags             0\n",
       "Time since posted    0\n",
       "Likes                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c8c55d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "99642564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we have 100 rows of data so we can impute is null values from dropping them\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "65cb4bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "S.No                 0\n",
       "USERNAME             0\n",
       "Caption              0\n",
       "Followers            0\n",
       "Hashtags             0\n",
       "Time since posted    0\n",
       "Likes                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8d75afb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S.No</th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Time since posted</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mikequindazzi</td>\n",
       "      <td>Who are #DataScientist and what do they do? &gt;&gt;...</td>\n",
       "      <td>1600</td>\n",
       "      <td>#MachineLearning #AI #DataAnalytics #DataScien...</td>\n",
       "      <td>11 hours</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>drgorillapaints</td>\n",
       "      <td>We all know where it’s going. We just have to ...</td>\n",
       "      <td>880</td>\n",
       "      <td>#deck .#mac #macintosh#sayhello #apple #steve...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  S.No         USERNAME  \\\n",
       "0           0     1    mikequindazzi   \n",
       "1           1     2  drgorillapaints   \n",
       "\n",
       "                                             Caption  Followers  \\\n",
       "0  Who are #DataScientist and what do they do? >>...       1600   \n",
       "1  We all know where it’s going. We just have to ...        880   \n",
       "\n",
       "                                            Hashtags Time since posted  Likes  \n",
       "0  #MachineLearning #AI #DataAnalytics #DataScien...          11 hours    139  \n",
       "1   #deck .#mac #macintosh#sayhello #apple #steve...           2 hours     23  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now we are having no null values in my dataset so we can check which colimns are required for target \n",
    "as in previewun named column and s.n column doesnot affect target so we can drop them '''\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3fe0c43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'S.No', 'USERNAME', 'Caption', 'Followers', 'Hashtags',\n",
       "       'Time since posted', 'Likes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "709ae9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'S.No',], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ed402d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USERNAME', 'Caption', 'Followers', 'Hashtags', 'Time since posted',\n",
       "       'Likes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9a3a1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the relevant features and target variables \n",
    "features=['USERNAME', 'Caption', 'Followers', 'Hashtags']\n",
    "t_Likes='Likes'\n",
    "t_Time_since_posted='Time since posted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a466be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[features]\n",
    "y_Likes=df[t_Likes]\n",
    "y_Time_since_posted=df[t_Time_since_posted]\n",
    "X_train,X_test,y_Likes_train,y_Likes_test,y_Time_since_posted_train,y_Time_since_posted_test=train_test_split(X,y_Likes,y_Time_since_posted,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "690f0002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e0db7812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text features using one-hot encoding\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_test_encoded = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b545e78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Likes): 1796.647477115598\n"
     ]
    }
   ],
   "source": [
    "# Train a model to predict the number of likes\n",
    "likes_model = LinearRegression()\n",
    "likes_model.fit(X_train_encoded, y_Likes_train)\n",
    "likes_predictions = likes_model.predict(X_test_encoded)\n",
    "likes_mse = mean_squared_error(y_Likes_test, likes_predictions)\n",
    "print(\"Mean Squared Error (Likes):\", likes_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2cdbef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training a model for time since posted \n",
    "import re\n",
    "def extract_num_val(time_string):\n",
    "    num_val=re.findall(r'\\d+',time_string)[0]\n",
    "    return int(num_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "651e7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Time_since_posted_train=y_Time_since_posted_train.apply(extract_num_val)\n",
    "y_Time_since_posted_test=y_Time_since_posted_test.apply(extract_num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7d28009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.367473082092502\n"
     ]
    }
   ],
   "source": [
    "time_since_posted_model=LinearRegression()\n",
    "time_since_posted_model.fit(X_train_encoded, y_Time_since_posted_train)\n",
    "time_since_posted_pred=time_since_posted_model.predict(X_test_encoded)\n",
    "time_since_posted_mse=mean_squared_error(y_Time_since_posted_test,time_since_posted_pred)\n",
    "print(time_since_posted_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d19b8",
   "metadata": {},
   "source": [
    "## Q-2. Imagine you have a dataset where you have different features like Age ,Gender , Height , Weight , BMI , and Blood Pressure and you have to classify the people into different classes like Normal , Overweight , Obesity , Underweight , and Extreme Obesity by using any 4 different classification algorithms. Now you have to build a model which can classify people into different classes.\n",
    "Dataset This is the Dataset You can use this dataset for this question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
