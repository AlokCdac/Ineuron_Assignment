{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50bbf05e",
   "metadata": {},
   "source": [
    "### Question-1. Write a program that takes a string as input, and counts the frequency of each word in the string, there might be repeated characters in the string. Your task is to find the highest frequency and returns the length of the highest-frequency word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d03794",
   "metadata": {},
   "outputs": [],
   "source": [
    " def word_count(str):\n",
    "    counts = dict()\n",
    "    words = str.split()\n",
    "\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "        max_key=max(counts,key=counts.get)\n",
    "        \n",
    "\n",
    "    return counts, len(max_key)\n",
    "\n",
    "word_count(input())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742076d2",
   "metadata": {},
   "source": [
    "### Question 2. Consider a string to be valid if all characters of the string appear the same number of times. It is also valid if he can remove just one character at the index in the string, and the remaining characters will occur the same number of times. Given a string, determine if it is valid. If so, return YES , otherwise return NO ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def isValid(s):\n",
    "    c = Counter(Counter(s).values())\n",
    "    if len(c)==1:\n",
    "        return \"YES\"\n",
    "    if len(c)>2:\n",
    "        return \"NO\"\n",
    "    if 1 in c.values() and (c[min(c.keys())]==1 or (max(c.keys()) - min(c.keys())==1)):\n",
    "        return \"YES\"\n",
    "    else:\n",
    "        return \"NO\"\n",
    "\n",
    "print(isValid(input()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd689473",
   "metadata": {},
   "source": [
    "### Question 3. Write a program, which would download the data from the provided link, and then read the data and convert that into properly structured data and return it in Excel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcfa3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "url='https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json' #provide valid url link to download data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2dc010e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(url)\n",
    "data=response.json()\n",
    "data1=data['pokemon']\n",
    "df=pd.DataFrame(data1,columns=['id',\n",
    "   'num',\n",
    "   'name',\n",
    "   'img',\n",
    "   'type',\n",
    "   'height',\n",
    "   'weight',\n",
    "   'candy',\n",
    "   'egg',\n",
    "   'spawn_chance',\n",
    "   'avg_spawns',\n",
    "   'spawn_time',\n",
    "   'multipliers',\n",
    "   'weaknesses',\n",
    "   'prev_evolution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3c4b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"pokemon_Excel.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625df54",
   "metadata": {},
   "source": [
    "### Question 4 -Write a program to download the data from the link given below and then read the data and convert the intothe proper structure and return it as a CSV file.\n",
    "Link - https://data.nasa.gov/resource/y77d-th95.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d02e3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1='https://data.nasa.gov/resource/y77d-th95.json' #provide valid url link to download data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92424d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa=requests.get(url1)\n",
    "data_nasa=nasa.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4d87fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nasa=pd.DataFrame(data_nasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76569b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nasa.to_csv('nasa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00d238",
   "metadata": {},
   "source": [
    "### Question 5 -Write a program to download the data from the given API link and then extract the following data withproper formatting\n",
    "Link - http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32226924",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2='http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes' #provide valid url link to download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c693b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "maze=requests.get(url2)\n",
    "pull_maze=maze.text\n",
    "data_maze=json.loads(pull_maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed3b963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season 1 Episode 1: The Original\n",
      "Season 1 Episode 2: Chestnut\n",
      "Season 1 Episode 3: The Stray\n",
      "Season 1 Episode 4: Dissonance Theory\n",
      "Season 1 Episode 5: Contrapasso\n",
      "Season 1 Episode 6: The Adversary\n",
      "Season 1 Episode 7: Trompe L'Oeil\n",
      "Season 1 Episode 8: Trace Decay\n",
      "Season 1 Episode 9: The Well-Tempered Clavier\n",
      "Season 1 Episode 10: The Bicameral Mind\n",
      "Season 2 Episode 1: Journey Into Night\n",
      "Season 2 Episode 2: Reunion\n",
      "Season 2 Episode 3: Virtù e Fortuna\n",
      "Season 2 Episode 4: The Riddle of the Sphinx\n",
      "Season 2 Episode 5: Akane No Mai\n",
      "Season 2 Episode 6: Phase Space\n",
      "Season 2 Episode 7: Les Écorchés\n",
      "Season 2 Episode 8: Kiksuya\n",
      "Season 2 Episode 9: Vanishing Point\n",
      "Season 2 Episode 10: The Passenger\n",
      "Season 3 Episode 1: Parce Domine\n",
      "Season 3 Episode 2: The Winter Line\n",
      "Season 3 Episode 3: The Absence of Field\n",
      "Season 3 Episode 4: The Mother of Exiles\n",
      "Season 3 Episode 5: Genre\n",
      "Season 3 Episode 6: Decoherence\n",
      "Season 3 Episode 7: Passed Pawn\n",
      "Season 3 Episode 8: Crisis Theory\n",
      "Season 4 Episode 1: The Auguries\n",
      "Season 4 Episode 2: Well Enough Alone\n",
      "Season 4 Episode 3: Années Folles\n",
      "Season 4 Episode 4: Generation Loss\n",
      "Season 4 Episode 5: Zhuangzi\n",
      "Season 4 Episode 6: Fidelity\n",
      "Season 4 Episode 7: Metanoia\n",
      "Season 4 Episode 8: Que Será, Será\n"
     ]
    }
   ],
   "source": [
    "for episode in data_maze[\"_embedded\"][\"episodes\"]:\n",
    "    print(f\"Season {episode['season']} Episode {episode['number']}: {episode['name']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ddff64",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff64ce",
   "metadata": {},
   "source": [
    "## Q-1. Imagine you have a dataset where you have different Instagram featureslike u sername , Caption , Hashtag , Followers , Time_Since_posted , and likes , now your task isto predict the number of likes and Time Since posted and the rest of the features areyour input features. Now you have to build a model which can predict thenumber of likes and Time Since posted.\n",
    "Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bdac9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "918e00bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('instagram_reach.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f5b03746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S.No</th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Time since posted</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mikequindazzi</td>\n",
       "      <td>Who are #DataScientist and what do they do? &gt;&gt;...</td>\n",
       "      <td>1600</td>\n",
       "      <td>#MachineLearning #AI #DataAnalytics #DataScien...</td>\n",
       "      <td>11 hours</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>drgorillapaints</td>\n",
       "      <td>We all know where it’s going. We just have to ...</td>\n",
       "      <td>880</td>\n",
       "      <td>#deck .#mac #macintosh#sayhello #apple #steve...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>aitrading_official</td>\n",
       "      <td>Alexander Barinov: 4 years as CFO in multinati...</td>\n",
       "      <td>255</td>\n",
       "      <td>#whoiswho #aitrading #ai #aitradingteam#instat...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>opensourcedworkplace</td>\n",
       "      <td>sfad</td>\n",
       "      <td>340</td>\n",
       "      <td>#iot #cre#workplace #CDO #bigdata #technology#...</td>\n",
       "      <td>3 hours</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>crea.vision</td>\n",
       "      <td>Ever missed a call while your phone was chargi...</td>\n",
       "      <td>304</td>\n",
       "      <td>#instamachinelearning #instabigdata#instamarke...</td>\n",
       "      <td>3 hours</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  S.No              USERNAME  \\\n",
       "0           0     1         mikequindazzi   \n",
       "1           1     2       drgorillapaints   \n",
       "2           2     3    aitrading_official   \n",
       "3           3     4  opensourcedworkplace   \n",
       "4           4     5           crea.vision   \n",
       "\n",
       "                                             Caption  Followers  \\\n",
       "0  Who are #DataScientist and what do they do? >>...       1600   \n",
       "1  We all know where it’s going. We just have to ...        880   \n",
       "2  Alexander Barinov: 4 years as CFO in multinati...        255   \n",
       "3                                               sfad        340   \n",
       "4  Ever missed a call while your phone was chargi...        304   \n",
       "\n",
       "                                            Hashtags Time since posted  Likes  \n",
       "0  #MachineLearning #AI #DataAnalytics #DataScien...          11 hours    139  \n",
       "1   #deck .#mac #macintosh#sayhello #apple #steve...           2 hours     23  \n",
       "2  #whoiswho #aitrading #ai #aitradingteam#instat...           2 hours     25  \n",
       "3  #iot #cre#workplace #CDO #bigdata #technology#...           3 hours     49  \n",
       "4  #instamachinelearning #instabigdata#instamarke...           3 hours     30  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d8b89391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "S.No                 0\n",
       "USERNAME             0\n",
       "Caption              6\n",
       "Followers            0\n",
       "Hashtags             0\n",
       "Time since posted    0\n",
       "Likes                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d30c3dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "91170692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we have 100 rows of data so we can impute is null values from dropping them\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2b074f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "S.No                 0\n",
       "USERNAME             0\n",
       "Caption              0\n",
       "Followers            0\n",
       "Hashtags             0\n",
       "Time since posted    0\n",
       "Likes                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9c8dd8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S.No</th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Time since posted</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mikequindazzi</td>\n",
       "      <td>Who are #DataScientist and what do they do? &gt;&gt;...</td>\n",
       "      <td>1600</td>\n",
       "      <td>#MachineLearning #AI #DataAnalytics #DataScien...</td>\n",
       "      <td>11 hours</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>drgorillapaints</td>\n",
       "      <td>We all know where it’s going. We just have to ...</td>\n",
       "      <td>880</td>\n",
       "      <td>#deck .#mac #macintosh#sayhello #apple #steve...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  S.No         USERNAME  \\\n",
       "0           0     1    mikequindazzi   \n",
       "1           1     2  drgorillapaints   \n",
       "\n",
       "                                             Caption  Followers  \\\n",
       "0  Who are #DataScientist and what do they do? >>...       1600   \n",
       "1  We all know where it’s going. We just have to ...        880   \n",
       "\n",
       "                                            Hashtags Time since posted  Likes  \n",
       "0  #MachineLearning #AI #DataAnalytics #DataScien...          11 hours    139  \n",
       "1   #deck .#mac #macintosh#sayhello #apple #steve...           2 hours     23  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now we are having no null values in my dataset so we can check which colimns are required for target \n",
    "as in previewun named column and s.n column doesnot affect target so we can drop them '''\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6579b03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'S.No', 'USERNAME', 'Caption', 'Followers', 'Hashtags',\n",
       "       'Time since posted', 'Likes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0f1c3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'S.No',], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "44976255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USERNAME', 'Caption', 'Followers', 'Hashtags', 'Time since posted',\n",
       "       'Likes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2d2aebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the relevant features and target variables \n",
    "features=['USERNAME', 'Caption', 'Followers', 'Hashtags']\n",
    "t_Likes='Likes'\n",
    "t_Time_since_posted='Time since posted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dfa9755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[features]\n",
    "y_Likes=df[t_Likes]\n",
    "y_Time_since_posted=df[t_Time_since_posted]\n",
    "X_train,X_test,y_Likes_train,y_Likes_test,y_Time_since_posted_train,y_Time_since_posted_test=train_test_split(X,y_Likes,y_Time_since_posted,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1e4bd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1d15374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text features using one-hot encoding\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_test_encoded = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "44f0a788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Likes): 1796.647477115598\n"
     ]
    }
   ],
   "source": [
    "# Train a model to predict the number of likes\n",
    "likes_model = LinearRegression()\n",
    "likes_model.fit(X_train_encoded, y_Likes_train)\n",
    "likes_predictions = likes_model.predict(X_test_encoded)\n",
    "likes_mse = mean_squared_error(y_Likes_test, likes_predictions)\n",
    "print(\"Mean Squared Error (Likes):\", likes_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d5154368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training a model for time since posted \n",
    "import re\n",
    "def extract_num_val(time_string):\n",
    "    num_val=re.findall(r'\\d+',time_string)[0]\n",
    "    return int(num_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "07408f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Time_since_posted_train=y_Time_since_posted_train.apply(extract_num_val)\n",
    "y_Time_since_posted_test=y_Time_since_posted_test.apply(extract_num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0145c317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.367473082092502\n"
     ]
    }
   ],
   "source": [
    "time_since_posted_model=LinearRegression()\n",
    "time_since_posted_model.fit(X_train_encoded, y_Time_since_posted_train)\n",
    "time_since_posted_pred=time_since_posted_model.predict(X_test_encoded)\n",
    "time_since_posted_mse=mean_squared_error(y_Time_since_posted_test,time_since_posted_pred)\n",
    "print(time_since_posted_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46dfcc0",
   "metadata": {},
   "source": [
    "## Q-2. Imagine you have a dataset where you have different features like Age ,Gender , Height , Weight , BMI , and Blood Pressure and you have to classify the people into different classes like Normal , Overweight , Obesity , Underweight , and Extreme Obesity by using any 4 different classification algorithms. Now you have to build a model which can classify people into different classes.\n",
    "Dataset This is the Dataset You can use this dataset for this question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "99d84466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fa0cbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1fcb14c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
       "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
       "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
       "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
       "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
       "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
       "\n",
       "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
       "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
       "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
       "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
       "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
       "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "\n",
       "                  MTRANS           NObeyesdad  \n",
       "0  Public_Transportation        Normal_Weight  \n",
       "1  Public_Transportation        Normal_Weight  \n",
       "2  Public_Transportation        Normal_Weight  \n",
       "3                Walking   Overweight_Level_I  \n",
       "4  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "61cda012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2111, 17)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1cc7df55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111 entries, 0 to 2110\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          2111 non-null   object \n",
      " 1   Age                             2111 non-null   float64\n",
      " 2   Height                          2111 non-null   float64\n",
      " 3   Weight                          2111 non-null   float64\n",
      " 4   family_history_with_overweight  2111 non-null   object \n",
      " 5   FAVC                            2111 non-null   object \n",
      " 6   FCVC                            2111 non-null   float64\n",
      " 7   NCP                             2111 non-null   float64\n",
      " 8   CAEC                            2111 non-null   object \n",
      " 9   SMOKE                           2111 non-null   object \n",
      " 10  CH2O                            2111 non-null   float64\n",
      " 11  SCC                             2111 non-null   object \n",
      " 12  FAF                             2111 non-null   float64\n",
      " 13  TUE                             2111 non-null   float64\n",
      " 14  CALC                            2111 non-null   object \n",
      " 15  MTRANS                          2111 non-null   object \n",
      " 16  NObeyesdad                      2111 non-null   object \n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 280.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ff107c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>2111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.312600</td>\n",
       "      <td>1.701677</td>\n",
       "      <td>86.586058</td>\n",
       "      <td>2.419043</td>\n",
       "      <td>2.685628</td>\n",
       "      <td>2.008011</td>\n",
       "      <td>1.010298</td>\n",
       "      <td>0.657866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.345968</td>\n",
       "      <td>0.093305</td>\n",
       "      <td>26.191172</td>\n",
       "      <td>0.533927</td>\n",
       "      <td>0.778039</td>\n",
       "      <td>0.612953</td>\n",
       "      <td>0.850592</td>\n",
       "      <td>0.608927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.947192</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>65.473343</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.658738</td>\n",
       "      <td>1.584812</td>\n",
       "      <td>0.124505</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.777890</td>\n",
       "      <td>1.700499</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2.385502</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.768464</td>\n",
       "      <td>107.430682</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.477420</td>\n",
       "      <td>1.666678</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age       Height       Weight         FCVC          NCP  \\\n",
       "count  2111.000000  2111.000000  2111.000000  2111.000000  2111.000000   \n",
       "mean     24.312600     1.701677    86.586058     2.419043     2.685628   \n",
       "std       6.345968     0.093305    26.191172     0.533927     0.778039   \n",
       "min      14.000000     1.450000    39.000000     1.000000     1.000000   \n",
       "25%      19.947192     1.630000    65.473343     2.000000     2.658738   \n",
       "50%      22.777890     1.700499    83.000000     2.385502     3.000000   \n",
       "75%      26.000000     1.768464   107.430682     3.000000     3.000000   \n",
       "max      61.000000     1.980000   173.000000     3.000000     4.000000   \n",
       "\n",
       "              CH2O          FAF          TUE  \n",
       "count  2111.000000  2111.000000  2111.000000  \n",
       "mean      2.008011     1.010298     0.657866  \n",
       "std       0.612953     0.850592     0.608927  \n",
       "min       1.000000     0.000000     0.000000  \n",
       "25%       1.584812     0.124505     0.000000  \n",
       "50%       2.000000     1.000000     0.625350  \n",
       "75%       2.477420     1.666678     1.000000  \n",
       "max       3.000000     3.000000     2.000000  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f1734c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111 entries, 0 to 2110\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          2111 non-null   object \n",
      " 1   Age                             2111 non-null   float64\n",
      " 2   Height                          2111 non-null   float64\n",
      " 3   Weight                          2111 non-null   float64\n",
      " 4   family_history_with_overweight  2111 non-null   object \n",
      " 5   FAVC                            2111 non-null   object \n",
      " 6   FCVC                            2111 non-null   float64\n",
      " 7   NCP                             2111 non-null   float64\n",
      " 8   CAEC                            2111 non-null   object \n",
      " 9   SMOKE                           2111 non-null   object \n",
      " 10  CH2O                            2111 non-null   float64\n",
      " 11  SCC                             2111 non-null   object \n",
      " 12  FAF                             2111 non-null   float64\n",
      " 13  TUE                             2111 non-null   float64\n",
      " 14  CALC                            2111 non-null   object \n",
      " 15  MTRANS                          2111 non-null   object \n",
      " 16  NObeyesdad                      2111 non-null   object \n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 280.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "31be4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to convert obj data into int so we areusing label encoder for same \n",
    "\n",
    "encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a0ddecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Gender']=encoder.fit_transform(df1['Gender'])\n",
    "df1['family_history_with_overweight']=encoder.fit_transform(df1['family_history_with_overweight'])\n",
    "df1['FAVC']=encoder.fit_transform(df1['FAVC'])\n",
    "df1['CAEC']=encoder.fit_transform(df1['CAEC'])\n",
    "df1['SMOKE']=encoder.fit_transform(df1['SMOKE'])\n",
    "df1['SCC']=encoder.fit_transform(df1['SCC'])\n",
    "df1['CALC']=encoder.fit_transform(df1['CALC'])\n",
    "df1['MTRANS']=encoder.fit_transform(df1['MTRANS'])\n",
    "df1['NObeyesdad']=encoder.fit_transform(df1['NObeyesdad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b0508c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111 entries, 0 to 2110\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          2111 non-null   int64  \n",
      " 1   Age                             2111 non-null   float64\n",
      " 2   Height                          2111 non-null   float64\n",
      " 3   Weight                          2111 non-null   float64\n",
      " 4   family_history_with_overweight  2111 non-null   int32  \n",
      " 5   FAVC                            2111 non-null   int32  \n",
      " 6   FCVC                            2111 non-null   float64\n",
      " 7   NCP                             2111 non-null   float64\n",
      " 8   CAEC                            2111 non-null   int32  \n",
      " 9   SMOKE                           2111 non-null   int32  \n",
      " 10  CH2O                            2111 non-null   float64\n",
      " 11  SCC                             2111 non-null   int32  \n",
      " 12  FAF                             2111 non-null   float64\n",
      " 13  TUE                             2111 non-null   float64\n",
      " 14  CALC                            2111 non-null   int32  \n",
      " 15  MTRANS                          2111 non-null   int32  \n",
      " 16  NObeyesdad                      2111 non-null   int32  \n",
      "dtypes: float64(8), int32(8), int64(1)\n",
      "memory usage: 214.5 KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cd84a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now spliting data into X and y \n",
    "X=df1.drop('NObeyesdad',axis=1)\n",
    "y=df1['NObeyesdad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9bbddf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "31695ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using decision tree classifier\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train,y_train)\n",
    "dt_pred=dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9f3d031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#using decision logistic regressor\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred=dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8d966bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using random forest classifier\n",
    "rf_clf=RandomForestClassifier()\n",
    "rf_clf.fit(X_train,y_train)\n",
    "rf_pred=rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "625d3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usinng svc\n",
    "svc_clf=SVC()\n",
    "svc_clf.fit(X_train,y_train)\n",
    "svc_clf_pred=svc_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c30d2c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        56\n",
      "           1       0.87      0.87      0.87        62\n",
      "           2       0.96      0.94      0.95        78\n",
      "           3       0.95      0.95      0.95        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       0.89      0.91      0.90        56\n",
      "           6       0.98      0.94      0.96        50\n",
      "\n",
      "    accuracy                           0.94       423\n",
      "   macro avg       0.94      0.94      0.94       423\n",
      "weighted avg       0.94      0.94      0.94       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing classification report of dt\n",
    "print(classification_report(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "85785424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        56\n",
      "           1       0.87      0.87      0.87        62\n",
      "           2       0.96      0.94      0.95        78\n",
      "           3       0.95      0.95      0.95        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       0.89      0.91      0.90        56\n",
      "           6       0.98      0.94      0.96        50\n",
      "\n",
      "    accuracy                           0.94       423\n",
      "   macro avg       0.94      0.94      0.94       423\n",
      "weighted avg       0.94      0.94      0.94       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing classification report of LR\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ad9b6d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.78        56\n",
      "           1       0.48      0.34      0.40        62\n",
      "           2       0.65      0.33      0.44        78\n",
      "           3       0.77      0.41      0.54        58\n",
      "           4       0.56      1.00      0.72        63\n",
      "           5       0.47      0.48      0.47        56\n",
      "           6       0.43      0.58      0.49        50\n",
      "\n",
      "    accuracy                           0.57       423\n",
      "   macro avg       0.58      0.57      0.55       423\n",
      "weighted avg       0.59      0.57      0.54       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing classification report of svc\n",
    "print(classification_report(y_test, svc_clf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "81f7e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf=RandomForestClassifier()\n",
    "rf_clf.fit(X_train,y_train)\n",
    "rf_pred=rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "025382c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        56\n",
      "           1       0.89      0.90      0.90        62\n",
      "           2       0.99      0.97      0.98        78\n",
      "           3       0.97      0.98      0.97        58\n",
      "           4       1.00      1.00      1.00        63\n",
      "           5       0.86      0.88      0.87        56\n",
      "           6       0.96      0.94      0.95        50\n",
      "\n",
      "    accuracy                           0.95       423\n",
      "   macro avg       0.95      0.95      0.95       423\n",
      "weighted avg       0.95      0.95      0.95       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing classification report of rfc\n",
    "print(classification_report(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c0da2",
   "metadata": {},
   "source": [
    "## Q-3. Imagine you have a dataset where you have different categories of data, Now you need to find the most similar data to the given data by using any 4 different similarity algorithms. Now you have to build a model which can find the most similar data to the given data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfe74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity,manhattan_distances,euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af54569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json('News_Category_Dataset_v3.json',lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d8d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting relevant columns \n",
    "df=df[['headline','category','short_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b588fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing of data \n",
    "df['new']=df['headline']+\"\"+df['short_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df127880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization of text data\n",
    "vect=TfidfVectorizer()\n",
    "X=vect.fit_transform(df['new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54942b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for finding similar data using fifferent algorithms\n",
    "def finding_sim_data(data,top_n=5):\n",
    "    data_vector=vect.transform([data])\n",
    "\n",
    "#calculating similarities using different algrithms\n",
    "\n",
    "    cosine_simi=cosine_similarity(X, data_vector).flatten()\n",
    "    euclad_simi=euclidean_distances(X, data_vector).flatten()\n",
    "    manhat_simi=manhattan_distances(X, data_vector).flatten()\n",
    "    \n",
    "    simi_score=(cosine_simi+euclad_simi+manhat_simi)/4\n",
    "    \n",
    "    top_indices=simi_score.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    similar_data=df.iloc(top_indices)\n",
    "    \n",
    "    return similar_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2213e18",
   "metadata": {},
   "source": [
    "assignment is continued but due to haevy schedule of last month unable to complete so pl consider if possible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11898d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
